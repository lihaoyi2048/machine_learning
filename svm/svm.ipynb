{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 支持向量机原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "支持向量机（Support Vector Machine，简称SVM），是机器学习中运用广泛的一种算法。SVM是一种二分类算法，通过构建超平面函数，来进行样本分类。  \n",
    "对于样本空间：\n",
    "$$T={(x_1,y_1),(x_2,y_2),\\cdots,(x_n,y_n)}$$\n",
    "其中，$x_i \\in \\mathbb{R}^{n}, y_i \\in{+1,-1},i=1,2,\\cdots,n$   \n",
    "$x_i$为第i个样本，$y_i$为$x_i$的类别标签。当$y_i=+1$时，称$x_i$为正例；当$y_i=-1$时，称$x_i$为负例。$(x_i,y_i)$成为样本点。  \n",
    "假设超平面决策边界函数为：\n",
    "$$W^TX+b=0$$\n",
    "其中$W=(W_1,W_2.\\cdots,W_n)$为法向量，决定了超平面的方向。$b$为位移项，决定了超平面与原点的距离。  \n",
    "任一点$X$到超平面的距离表示为：\n",
    "$$r=\\frac{|W_TX+b|}{\\left| W \\right|}$$\n",
    "$\\left| W \\right|$表示法向量的模。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设超平面$(W,b)$能对样本进行正确的分类，那么对于$(x_i,y_i) \\in T$，若$y_i=+1$，则有$W_TX_i+b>0$，相反地，若$y_i=-1$，则有$W_TX_i+b<0$。我们假设\n",
    "$$\n",
    "\\begin{cases}\n",
    "W^TX_i+b >= 0 ,& \\text{ if } y_i=+1 \\\\ \n",
    "W^TX_i+b <= 0 ,& \\text{ if } y_i=-1\n",
    "\\end{cases}\n",
    "$$\n",
    "上面两公式的间隔可表示为\n",
    "$$\\frac{2}{\\left| W \\right|}$$\n",
    "我们的目的是求最大间隔\n",
    "$$\\max_{{W,b}} \\frac{2}{\\left| W \\right|}$$\n",
    "其中$y_i(W_TX_i+b)>=1,i=1,2,\\cdots,n$。  \n",
    "将最大化问题转为最小化问题：\n",
    "$$\\min_{{W,b}} \\frac{1}{2}\\left| W \\right|^2$$\n",
    "其中$y_i(W_TX_i+b)>=1,i=1,2,\\cdots,n$。  \n",
    "这就是支持向量的基本型，即优化目标函数。  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**模型为：**\n",
    "$$f(x)=W^Tx+b=\\sum_{i=1}^{m}\\alpha_iy_ix_i^Tx+b$$\n",
    "KTT条件为：\n",
    "$$\n",
    "\\left\\{\\begin{matrix}\n",
    "\\alpha_i \\geq 0\\\\ \n",
    "y_i f(x_i)-1 \\geq 0\\\\ \n",
    "\\alpha_i(y_if(x_i)-1)=0\n",
    "\\end{matrix}\\right.\n",
    "$$\n",
    "**优化的目标函数：**\n",
    "$$\\max_{{\\alpha}} \\sum_{i=1}^{m}\\alpha_i-\\frac{1}{2} \\sum_{i=1}^{m}\\sum_{j=1}^{m}\\alpha_i \\alpha_j y_i y_j x_i x_j$$\n",
    "  $$s.t. \\, \\sum_{i=1}^{m}\\alpha_i y_i=0,  \\alpha_i \\geq,i=1,2,\\cdots,m$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 算法7.1\n",
    "**线性可分支持向量机学习算法--最大间隔法**\n",
    "输入：线性可分训练数据集$T={(x_1,y_1),(x_2,y_2),\\cdots,(x_N,y_N)}$，\n",
    "其中$x_i \\in \\mathbb{R}$，$y_i={+1,_1}$，$i=1,2,\\cdots,N$；  \n",
    "输出：最大间隔分离超平面和分类决策函数。  \n",
    "（1）构造并求解约束最优化问题：\n",
    "$$$$ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
